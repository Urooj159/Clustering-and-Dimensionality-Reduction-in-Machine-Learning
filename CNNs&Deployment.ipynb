{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKDKBjor3DtjCZvMNJs2Zf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Urooj159/Clustering-and-Dimensionality-Reduction-in-Machine-Learning/blob/main/CNNs%26Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📍 STEP 1: Install Streamlit & Ngrok in Google Colab\n",
        "!pip install streamlit pyngrok --quiet\n",
        "\n",
        "# Import Ngrok to create a public link later\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any existing ngrok processes (avoids \"address already in use\" errors)\n",
        "ngrok.kill()\n",
        "\n",
        "# 📍 STEP 2: Training Code (Your Existing Code)\n",
        "# ======================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import os\n",
        "\n",
        "# Example Dataset: Flowers (replace with your dataset path)\n",
        "# Download small flowers dataset for testing\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
        "!tar -xzf flower_photos.tgz\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "DATA_DIR = \"/content/flower_photos\"\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_data = train_gen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = train_gen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "num_classes = train_data.num_classes\n",
        "class_names = list(train_data.class_indices.keys())\n",
        "\n",
        "def build_model(base_model):\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "base_model_mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model = build_model(base_model_mobilenet)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(\"model.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=3,  # small for quick test\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# 📍 STEP 3: Create Streamlit UI\n",
        "\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load model\n",
        "model = load_model(\"model.h5\")\n",
        "\n",
        "# Class names\n",
        "class_names = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_image(img):\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    return np.expand_dims(img_array, axis=0)\n",
        "\n",
        "st.title(\"🌸 Flower Image Classifier\")\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "if uploaded_file:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "    processed = preprocess_image(image)\n",
        "    prediction = model.predict(processed)[0]\n",
        "    predicted_class = class_names[np.argmax(prediction)]\n",
        "    confidence = np.max(prediction)\n",
        "    st.success(f\"Prediction: **{predicted_class}** ({confidence:.2f})\")\n",
        "\n",
        "    st.subheader(\"Top 3 Predictions:\")\n",
        "    top_3_indices = prediction.argsort()[-3:][::-1]\n",
        "    for i in top_3_indices:\n",
        "        st.write(f\"{class_names[i]}: {prediction[i]:.2f}\")\n",
        "\n",
        "\n",
        "# 📍 STEP 4: Run Streamlit with Ngrok\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill previous tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Start new tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit App URL: {public_url}\")\n",
        "\n",
        "!streamlit run app.py &>/dev/null&\n"
      ],
      "metadata": {
        "id": "I1KcCDn0S8MQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ce7a9a-c58c-4010-b179-a4bae58eb444"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2939 images belonging to 5 classes.\n",
            "Found 731 images belonging to 5 classes.\n",
            "Epoch 1/3\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6591 - loss: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6601 - loss: 0.9246 - val_accuracy: 0.8345 - val_loss: 0.4744\n",
            "Epoch 2/3\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8518 - loss: 0.3965"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 2s/step - accuracy: 0.8518 - loss: 0.3965 - val_accuracy: 0.8482 - val_loss: 0.4366\n",
            "Epoch 3/3\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8743 - loss: 0.3550"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 2s/step - accuracy: 0.8743 - loss: 0.3550 - val_accuracy: 0.8536 - val_loss: 0.3989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%%writefile` not found.\n"
          ]
        }
      ]
    }
  ]
}